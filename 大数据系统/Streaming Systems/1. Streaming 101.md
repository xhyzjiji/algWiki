# 流式系统概述

## 1. 流 VS 批

几个观点：

1. 批和流实际上是能统一的

2. 流/批处理数据的不同点，主要是无界（unbounded）和无序（unordered）这两个方面。
   
   | 数据特征 | 批处理系统 | 流处理系统 |
   | ---- | ----- | ----- |
   | 数据边界 | 有界    | 无界    |
   | 数据顺序 | 有序    | 无序    |

3. 流/批系统区别
   
   | 系统类别 | 数据视图            | 有无状态 | failover                                                               | 数据吞吐量                                         | 流join         |
   | ---- | --------------- | ---- | ---------------------------------------------------------------------- | --------------------------------------------- | ------------- |
   | 批处理  | table（近”全局“数据）  | 无状态  | 重做                                                                     | “全局”数据视图，有针对性的性能优化，吞吐量高                       | “全局”数据视图，实现简单 |
   | 流处理  | stream（实时+历史数据） | 有状态  | 1. checkpoint+ 重做（flink的做法，隐含了事务性和全局回滚）<br/>2. at-least-once + 重试<br/> | 需要在实时性、准确性上做权衡；无法做过多的复杂处理（或者需要分布式节点分工地处理复杂运算） | 因为数据无序、无界变得困难 |
   
   > :question: 批处理系统结果一定正确吗？
   > 
   > 批处理结果也不一定是准确的。
   > 
   > 1. 移动端数据可能延迟到达：假设一个移动设备数据延迟3~5天到达系统，T+1报表数据就可能不准确；即使重算数据，也无法确定应该重做多长时间之前的数据
   > 
   > 2. 对于Session窗口，一个Session可以持续很长时间，比如设备的监控、游戏用户数据、风控、系统异常行为等，不同设备、用户一次Session时间跨度是不确定的，按固定窗口截断的数据，计算结果可能不准。
   > 
   > 总的来说，计算逻辑所需要的上下文越完整，结果越准确。

综上所述，流处理系统功能可以涵盖批处理系统，并且系统应以”数据特征：1.数据规模，2.数据组织方式（stream or table）“进行区分。

## 2. 数据组织形式（Stream VS Table）

> :notes: stream 和 table 是可以互相转换的
> 
> stream -> table: stream 数据随着时间推移聚合成 table（比如：DB的database、ES的index）
> 
> table -> stream: table 随时间推移产生的可观察变更形成了 stream（比如：WAL）

那么就会有4中具体的转换场景：

| 数据组织方式转换         | 说明                                                                                                                      | 应用                         |
| ---------------- | ----------------------------------------------------------------------------------------------------------------------- | -------------------------- |
| stream -> stream | nongrouping operation，或者说是对单个元素的处理（filter/map等），很好理解，storm等传统意义上的流处理都是针对的这种情况                                           | 1. 流拓扑图中stage之间的数据shuffle  |
| stream -> table  | grouping operation，或者说是需要shuffle的操作，shuffle后每个operator需要保存一个internal state，其实就是这个所谓的table，典型的就是各种聚合（参考spark中的stage划分策略） | 1. 生成的中间态<br/>2. 实时同步数仓数据湖 |
| table -> stream  | ungrouping operation，典型的就是dataflow中的各种trigger                                                                           | 1. CDC                     |
| table -> table   | 不存在，所有对table的修改都是通过先ungroup再group实现的                                                                                    |                            |

而促使上面的转换，需要经过系统的operation来完成。

也就是说，<font color = 'red'>任何data processing system，无论流还是批，其实就3个要素：stream、table、operation。</font>

## 3. 中间状态

## 4. exactly-once和强一致性

要实现exactly-once语义，需要从3个方面入手：

* shuffle：every record is shuffled exactly once，或者说是系统内部的exactly-once语义。非shuffle的场景下（比如单个stage内）通常都能隐式的保证exactly-once。

> 思路：
> 
> storm 的 ack 机制（发送端和接收端同时维护一个onflight（在路上，未经双方确认）的消息map<id, msg>，同时利用graph optimization、bloom filter等技术提高效率。

* source：every source record is processed exactly

> 思路：
> 
> kafka 和 RocketMQ 使用 msgId 作为半事务唯一识别 + 事务回查（生产端需要保存已发送的事务状态），或者依赖shared storage的幂等性（去重 + 幂等）

* sink：every sink produces accurate output

> 思路：
> 
> 1. Idempotent updates：sink还是可能重跑，输出多个重复值，但存储系统是幂等方式存储的，比如文件、KV这种每次覆盖；
> 
> 2. Transactional updates：这个比较好理解，如果retry，上一次输出的值其实没有commit；
