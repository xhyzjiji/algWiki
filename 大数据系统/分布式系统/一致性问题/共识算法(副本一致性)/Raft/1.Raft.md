# 1 协议简介

Raft比Paxos容易理解和实现，主要归功于作者把一致性问题划分成3个相对独立的问题：

1. 日志复制（问题：已提交的不能被覆盖，那怎么样的日志才算已提交？日志记录单点下的空间应该如何管理？）

2. leader选举（问题：集群如何无中生有一个leader的？如何保证新Leader不会错误覆盖已提交的日志？）

3. 成员变更（问题：在新节点加入或离开集群的时候，如何保证一个时刻，集群不受影响保证只有一个leader？）

其中，leader选举和成员变更都受日志复制，日志提交影响。

Raft协议提供下面的保证：

![](/Users/panyongfeng/Documents/basic_framework/wiki/大数据系统/分布式系统/一致性问题/共识算法(副本一致性)/pics/1578998929.png)

1. 一个时刻最多只有一个节点可以称为Leader（受限于单点性能，所以才有了Raft Group）

2. <font color='red'>Leader不会覆盖或删除自身的日志</font>，但是Leader可以让Follower覆盖和删除日志

3. 如果两个副本中，日志的数量和顺序都一样，那么他们是一致的，也就是说，同一个log index位置的日志，在各个副本中应该相同

4. 日志一旦被提交，就一定会出现在后面所有任期上（<font color='red'>已提交的日志不丢失</font>，不被覆盖）

## 1.1 leader选举

（1）什么时候会发生选举？

![](/Users/panyongfeng/Documents/basic_framework/wiki/大数据系统/分布式系统/一致性问题/共识算法(副本一致性)/pics/1578801204.png)

选举的状态流转过程

- 在节点启动之后，默认都是Follower

- 当集群中有Follower的选举超时（即超过一定时间没有收到Leader的RPC请求）

- 当Candidate和Follower收到来自更大的Term的Leader发过来的信息时，立即退化成Follower

- Candidate会广播Vote RPC让集群内其他节点为自己投票
  
  > 投票者遵循以下原则：
  > 
  > 1. 投票者在一个Term下，只投给一个节点
  > 
  > 2. 当投票者收到>=节点自身的Term时，才能投赞成票，如果遇到更大的Term会立即更新自己的Term
  > 
  > 3. 投票者只有在Candidate日志更新，才会投赞成票
  > 
  > ![](/Users/panyongfeng/Documents/basic_framework/wiki/大数据系统/分布式系统/一致性问题/共识算法(副本一致性)/pics/1578666972.png)
  > 
  > 注：投票者指的是Follower和Candidate，Leader收到更大的Term时就会退位成Follower

- 当Candidate收到多数派的赞成票时，就会当选Leader
  
  > :leaves:  Multi Paxos里面提到，可能多个节点先后发生选主提议，导致一个集群出现多个Leader（所以当选Leader 不等于 上任Leader）
  > 
  > S1: 1 2  
  > S2: 1 2  
  > S3: 1 2
  > 
  > 假设，集群重启，S1在选举超时发起选举（Term=1），并且S2由于网络故障无法与{S1,S3}通信，S1获得{S1,S3}的赞成票，当选Leader
  > 
  > S1: 1 2 (Leader)  
  > S2: 1 2  
  > S3: 1 2
  > 
  > 由于S2网络隔离导致S2转入Candidate状态，并发起多次选举，到了Term=3时，恢复通信，并且S2获得{S2,S3}的赞成票，当选Leader
  > 
  > S1: 1 2 ({S1,S3} Vote, Leader)  
  > S2: 1 2 ({S2,S3} Vote, Leader)  
  > S3: 1 2
  > 
  > 因此，解决方法跟Multi Paxos一样，在Leader被选出后，会立即发送一个no-op事件来确认自己是否能上任Leader。
  > 
  > :warning:  事先说明下这个no-op事件的不同用途：（1）用于提交之前任期的日志（2）防止其他candidate发起选举（3）Leader确认自己上任（见其他小节）

（2）选举失败

同一时刻，可能有多个Candidate广播Vote RPC，如果大家都无法获得多数派支持，那么这一个Term的选举就被宣告失败。这个时候可能出现一个Term内可能完全没有内容可应用到状态机。

![](/Users/panyongfeng/Documents/basic_framework/wiki/大数据系统/分布式系统/一致性问题/共识算法(副本一致性)/pics/1578991634.png)

出现选举失败，在网络正常的情况下，就是选票被瓜分到不同的Candidate中，Raft为了简化设计，让Candidate选举<font color='red'>超时时间随机化</font>（Paxos篇提及用于规避异步化模型的手段），来降低选票瓜分的概率。

> :leaves:  文中也提及，是否让节点间有优先级来选择Leader，但是论文解释说会有一点小问题，猜测是网络分区+成员变更的问题，有兴趣的同学可以继续深挖一下。

## 1.2 日志复制

日志复制在Paxos篇已经提及，就是各个副本中维护一个状态机，每个操作作为一个操作日志记录到副本本地，如果各个副本中的操作日志完全一致（数量和顺序），那么应用到状态机后，状态机所处状态也是可以保证一致的。

Leader通过AppendEntries RCP请求广播日志到各个副本节点，副本节点无条件信任Leader并写入本地日志。

![](/Users/panyongfeng/Documents/basic_framework/wiki/大数据系统/分布式系统/一致性问题/共识算法(副本一致性)/pics/1579231655.png)

日志属性：

1. 日志所在位置log index

2. 日志被写入时的任期号term

3. 日志的操作记录

为了讨论方便，下面讨论的时候都按下面的格式描述

![](/Users/panyongfeng/Documents/basic_framework/wiki/大数据系统/分布式系统/一致性问题/共识算法(副本一致性)/pics/1579773054.png)

### 1.2.1 日志一致性检查

1. 副本间日志如何保持一致？
   
   1. Leader被选出后，默认所有副本的日志与Leader本身一致（即，自身下一个日志可写位也是副本日志的下一个日志可写位）
   
   2. 当副本收到Leader发送过来的AppendEntries RPC，副本会检查Leader要写的logindex和该log的term，如果与Leader不一致则拒绝日志
      
      ![](/Users/panyongfeng/Documents/basic_framework/wiki/大数据系统/分布式系统/一致性问题/共识算法(副本一致性)/pics/1579707160.png)
   
   3. Leader的AppendEntries RPC被拒绝后，会尝试回退上一个日志位置，重试发送AppendEntries RPC，直到副本接受为止
      
      集群各副本的日志在某一时刻可能是下面的样子：
      
      ![](/Users/panyongfeng/Documents/basic_framework/wiki/大数据系统/分布式系统/一致性问题/共识算法(副本一致性)/pics/1579897438.png)
      
      Leader首先要找到各个副本与自己本身日志匹配的位置writeIndex后，重写或者填充副本的日志。
      
      ![](/Users/panyongfeng/Documents/basic_framework/wiki/大数据系统/分布式系统/一致性问题/共识算法(副本一致性)/pics/1580752222.png)
      
      > :leaves:  Leader需要维护各个副本的日志写入位置writeIndex

2. 副本之间的日志如何比较“新”和“旧”
   
   Raft 通过比较两个副本日志中最后一条日志条目的索引值和任期号来定义谁的日志比较新。
   
   1. 如果两份日志最后条目的任期号不同，那么任期号大的日志更“新”
   
   2. 如果两份日志最后条目的任期号相同，那么拥有更多日志的那个更“新”（即副本的last log index大的更“新”）。

### 1.2.2 关于“日志提交”的问题

日志什么时候才算被安全提交？

![](/Users/panyongfeng/Documents/basic_framework/wiki/大数据系统/分布式系统/一致性问题/共识算法(副本一致性)/pics/1566468573.png)

（a）S1为Leader（Term=2），并将日志（Term=2, logIndex=2）广播到副本，但是没有达到多数派时，宕机（S1，S2的Term=2，S3，S4，S5的Term=1）

（b）S5由{S3,S4,S5}投票选出作为Term=3的Leader，并收到一个请求，但S5仅添加到本地日志（Term=3, logindex=2）就宕机了（S1，S2的Term=2，S3，S4的Term=1，S5的Term=3）

（c）S1恢复（Term=4），并可获得{S1,S2,S3,S4}的赞成票，S1重新成为Leader，并继续恢复其他副本的日志（Term=2，logindex=2），并接收到新的请求（Term=4，logindex=3）（S1，S2，S3的Term=4，S4的Term=1，S5的Term=3）

然后根据日志复制原则，可能出现一下两种情形：

（d1）S1宕机，S5因为持有（Term=3，logindex=2）的日志，所以，他比{S2,S3,S4}的日志都要“新”，所以S5顺利成章当选Leader（假设S5以Term=4进行投票，节点是允许应答Term相同的RPC请求），然后S5同步（Term=3, logindex=2）的日志重写所有副本的数据（S1，S2，S3，S4，S5的Term=4）

（d2）S1继续运行，把（Term=4，logindex=3）的日志写入多数派，然后即使S1宕机，S5因为不具备最新日志，无法成为Leader

这两种情形都符合Raft协议的要求，但是（d1）的情形，已经被多数副本写入的数据却可能被其他日志覆盖，所以，<font color='red'>写多数派仅仅是Raft日志提交的必要条件</font>。

Raft日志还有一个规定：<font color='red'>（1）Leader只能提交自己所在Term的日志（也就是说，自身Term的日志只要写多数派之后就算提交）（2）早期Term日志重新复制到其他副本时，保留原有的Term，且这些日志即使写多数派也不能算已提交。</font>

> 回想一下Paxos协议中的重确认和幽灵日志。
> 
> 这种场景对应于Paxos篇中，即使提议已经提交，当存在该日志的一个节点宕机，原本多数派的日志会变成少数派。
> 
> Proposer： 1 2 3  
> ~~Acceptor1：1 2 3~~  
> Acceptor2：1 2
> 
> 当已提交的日志中有一个节点宕机，仅凭现状是无法得知日志是否被多数派接受
> 
> 外部视图：
> 
> Proposer：1 2 3  
> Acceptor：1 2
> 
> 根据视图推断的场景：
> 
> （1）场景1
> 
> Proposer：1 2 3  
> Acceptor：1 2  
> Acceptor：1 2
> 
> （2）场景2
> 
> Proposer：1 2 3  
> Acceptor：1 2 3  
> Acceptor：1 2
> 
> 但是我们永远不知道是哪种场景，所以Paxos索性对这些不确定的日志进行“重确认”（reconfiguration）：重新投票决定
> 
> Raft与Paxos的区别在于：1. Raft不允许日志空洞存在，如果有副本日志落后比较多，会导致副本长时间无法参与提交最新的日志；2. Raft一个位置的日志一旦提交，比这个位置更小的日志也是已提交的；
> 
> 所以Raft在新Leader当选后，可以立即发送一个no-op日志来提交之前任期的日志，而无需对之前的日志进行“重确认”（如果no-op日志还没提交，Leader就宕机，之前的日志相当于未提交，新Leader有权覆盖这些日志）。

> 附：Leader选举安全性证明
> 
> Leader选举安全性证明
> 
> ![](/Users/panyongfeng/Documents/basic_framework/wiki/大数据系统/分布式系统/一致性问题/共识算法(副本一致性)/pics/1579450284.png)
> 
> 假设：任期 T 的 leader（leader T）在任期内提交了一个日志条目，但是该日志条目没有被存储到未来某些任期U的 leader 中（U>T），我们用反证法推断假设不成立。
> 
> Leader选举的要求是新Leader的日志要比赞成者的日志“新”，“新”的定义是最后一个日志Term更大，如果Term一样就是logindex更大。
> 
> 有两种情况：
> 
> 1. 如果Leader U最后一个日志term跟投票者一样，那么日志一定比投票者要多，而投票者要求多数派，必定与任期T的已提交日志节点重叠（图中的S3）那么肯定包含已提交的AE日志，这个跟假设矛盾。
> 
> 2. 如果Leader U最后一个日志term比投票者大，那么比这个任期U小的已提交的日志应该都跟之前任期的leader一致，因为T<U，所以Leader U会包含Leader T的所有已提交日志，这个也跟假设矛盾。
> 
> 因此，我们的假设不成立，即新任期U必定包含任期T的全部已提交日志

## 1.3 成员变更

### 1.3.1 二阶段成员变更

到目前为止，我们都假设集群的配置（参与一致性算法的服务器集合）是固定不变的。但是在实践中，偶尔会改变集群的配置的，例如替换那些宕机的机器或者改变复制程度。尽管可以通过使整个集群下线，更新所有配置，然后重启整个集群的方式来实现，但是在更改期间集群会不可用。另外，如果存在手工操作步骤，那么就会有操作失误的风险。为了避免这样的问题，配置变更自动化也纳入到 Raft 一致性算法中来。

![](/Users/panyongfeng/Documents/basic_framework/wiki/大数据系统/分布式系统/一致性问题/共识算法(副本一致性)/pics/1579361510.png)

成员变更的配置同样是一个共识问题，但是在变更过程中，由于集群数量的变化，可能在共识过程中，不同的成员配置对多数派的要求不同，从而存在多个Leader在不同的成员配置中诞生，如上图（加入2个新节点）的：

- Cold：{S1, S2}，认为集群节点数是3个，多数派要求2个

- Cnew: {S3, S4, S5} ，认为集群节点数是5个，多数派要求3个

（1）在《In Search of an Understandable Consensus Algorithm》文中，二阶段变更：

Cold -> Cold,new -> Cnew，其中 Cold,new 是一个过渡态

![](/Users/panyongfeng/Documents/basic_framework/wiki/大数据系统/分布式系统/一致性问题/共识算法(副本一致性)/pics/1579397749.png)

Server对成员配置，需要遵循下面的原则：

1. 当节点已收到成员配置变更请求，不管这个提案是否已经提交（同步到多数派），本节点立即按新配置执行（比如Leader收到新配置，新配置中不属于集群的节点，Leader就不会再发送RPC请求）
   
   > 1. 在etcd的issue里，有用户提及二阶段成员变更问题：[https://github.com/etcd-io/etcd/issues/12359（learner的由来请看：[etcd](https://github.com/etcd-io/etcd/issues/12359%EF%BC%88learner%E7%9A%84%E7%94%B1%E6%9D%A5%E8%AF%B7%E7%9C%8B%EF%BC%9A%5Betcd) learner design | etcd]([https://etcd.io/docs/v3.5/learning/design-learner/)）](https://etcd.io/docs/v3.5/learning/design-learner/)%EF%BC%89)
   >    
   >    不过这个issue的用户没有注意成员变更的原则：
   >    
   >    1. 成员配置变更是节点接收到后立即应用
   >    
   >    2. 不在集群的成员，如果收到RPC请求，是可以应答符合条件的请求的（不会根据成员名单应答）
   > 
   > 我们再看issue里列举的场景：
   > 
   > Cold => voters: {A, B, C}, learners: {D}  
   > Cnew => voters: {A, B, D}, learners: {C}  
   > Cold,new => voters: {A, B, C, D}
   > 
   > 首先，A为Leader，B宕机，Leader收到成员变更请求并广播Cold,new到多数节点
   > 
   > A: ... Cold,new, E … En … Em （Leader）  
   > B: ...  
   > C: ... Cold,new, E … En  
   > D: ... Cold,new, E … En … Em
   > 
   > 然后，A宕机，B恢复，issue认为只有B、C可以进入Candidate并进行Leader选举，其实D已经应用Cold,new，已经不是learner状态，这时候D可以成为Leader（而B虽然在Cold，只认{A,B,C}，但是日志不比C新，无法成为Leader，而C应用Cold,new，认{A,B,C,D}，但是日志没有D新，所以不会被选为Leader）
   > 
   > ~~A: ... Cold,new, E … En … Em~~  
   > B: ...  
   > C: ... Cold,new, E … En  
   > D: ... Cold,new, E … En … Em （Leader）
   > 
   > 其他场景也能按上面的逻辑解释。

2. 在成员变更过程中，一旦发生选举，新Leader只可能在Cold或者Cold,new中被选出，所以Vote RPC可能会发往新加入的节点
   
   > 比如源集群有3个节点，现在需要增加2个节点，是的集群变为5节点
   > 
   > S1: Cold (Leader)  
   > S2: Cold  
   > S3: Cold  
   > S4:  
   > S5:
   > 
   > Leader收到新的配置请求Cnew = {S1,S2,S3,S4,S5}，Cold,new = Cold U Cnew = {S1,S2,S3,S4,S5}
   > 
   > ~~S1: Cold,new (Leader)~~  
   > S2: Cold  
   > S3: Cold  
   > S4: Cold,new  
   > S5:
   > 
   > 当Leader宕机，新Leader可以在Cold: {S2, S3} 选出S2/S3 或者 Cold,new: {S4,S2,S3,S5}中选出S4，只不过在Cold中选出的Leader无法感知成员变更的事情（S4 会在选举超时后发起新一轮选举，但如果期间{S2,S3}有新日志提交，可能S4无法被选为主），这个时候发起成员变更请求的客户端应答确定集群状态并重新发起。

3. 成员变更需要共用一个日志记录，否则会出现已提交的数据丢失的情况
   
   > data conf  
   > S1: 1 2 C0 (Leader)  
   > S2: 1 C0  
   > S3: 1 C0  
   > S4: 1 2 C0  
   > S5: 1 2 C0
   > 
   > 然后收到C1 = {S1, S2, S3, S4}
   > 
   > data conf  
   > S1: 1 2 C0 C1 (Leader)  
   > S2: 1 C0 C1  
   > S3: 1 C0 C1  
   > S4: 1 2 C0  
   > S5: 1 2 C0 (leave)
   > 
   > 然后再收到C2 = {S1, S2, S3}
   > 
   > data conf  
   > S1: 1 2 C0 C1 C2 (Leader)  
   > S2: 1 C0 C1 C2  
   > S3: 1 C0 C1 C2  
   > S4: 1 2 C0 C1 (leave)  
   > S5: 1 2 C0 (leave)
   > 
   > 此时，一旦S1故障发生选主，假设S2被选出，然后提交新的日志，S1恢复
   > 
   > data conf  
   > S1: 1 3 C0 C1 C2  
   > S2: 1 3 C0 C1 C2 (Leader)  
   > S3: 1 3 C0 C1 C2  
   > S4: 1 2 C0 C1 (leave)  
   > S5: 1 2 C0 (leave)
   > 
   > 日志2被覆盖，已提交的数据丢失

### 1.3.2 一阶段成员变更

在博士论文中，对二阶段成员变更，通过单节点成员变更，把二阶段优化成一阶段：Cold -> Cnew

![](/Users/panyongfeng/Documents/basic_framework/wiki/大数据系统/分布式系统/一致性问题/共识算法(副本一致性)/pics/1568546100.png)

两种情况：

（1）如果Cnew未过半前，Leader故障，可以从Cold上选出一个Leader服务，新Leader被选出后会先广播本term的no-op日志来提交之前的所有日志，所以原来的拥有Cnew的节点（旧term）无法被选出，Cold->Cnew的请求宣告失败；

（2）如果Cnew过半，属于已提交，那么持有Cold的服务就无法再被选为Leader了，即使新Leader故障，新选出的Leader都会持有Cnew配置

事实上，一阶段优化在并发成员变更可能带来脑裂（在不同的配置上出现多个leader），https://groups.google.com/g/raft-dev/c/t4xj6dJTP6E，下面拿其中一个例子说明：

> 增加一个节点到4节点集群然后再增加一个节点，配置如下：
> 
> C = {S1,S2,S3,S4}  
> D = {S1,S2,S3,S4,S5}  
> E = {S1,S2,S3,S4,S6}
> 
> （1）集群初始状态：
> 
> S1 (L1): [C]  
> S2 (F1): [C]  
> S3 (F1): [C]  
> S4 (F1): [C]  
> S5 (F1): []  
> S6 (F1): []
> 
> （2）S1收到新成员配置请求D并应用
> 
> S1 (L1): [C, D]  
> S2 (F1): [C]  
> S3 (F1): [C]  
> S4 (F1): [C]  
> S5 (F1): [C]
> 
> （3）S1将日志D复制到S5后宕机
> 
> ~~S1 (L1): [C, D]~~  
> S2 (F1): [C]  
> S3 (F1): [C]  
> S4 (F1): [C]  
> S5 (F1): [C, D]  
> S6 (F1): []
> 
> （4）S2发起选举，并从{S2,S3,S4}中获得赞成票成为Leader
> 
> ~~S1 (L1): [C, D]~~  
> S2 (L2): [C]  
> S3 (F2): [C]  
> S4 (F2): [C]  
> S5 (F1): [C, D]  
> S6 (F1): []
> 
> （5）S2收到新成员配置请求E并应用
> 
> ~~S1 (L1): [C, D]~~  
> S2 (L2): [C, E]  
> S3 (F2): [C]  
> S4 (F2): [C]  
> S5 (F1): [C, D]
> 
> （6）S2将E复制到S3和S6，此时在配置E中是已提交的状态（可以假设还有其他的日志）
> 
> ~~S1 (L1): [C, D]~~  
> S2 (L2): [C, E]  
> S3 (F2): [C, E]  
> S4 (F2): [C]  
> S5 (F1): [C, D]  
> S6 (F2): [C, E]
> 
> （7）S1发起选举，并得到{S1,S4,S5}赞成成为Leader
> 
> S1 (L3): [C, D]  
> S2 (L2): [C, E]  
> S3 (F2): [C, E]  
> S4 (F3): [C]  
> S5 (F3): [C, D]  
> S6 (F2): [C, E]
> 
> （8）S1根据自身配置覆盖副本日志
> 
> S1 (L3): [C, D]  
> S2 (L2): [C, D]  
> S3 (F2): [C, D]  
> S4 (F3): [C, D]  
> S5 (F3): [C, D]  
> S6 (F3): [C, D]
> 
> 上面的场景违背了两个地方：
> 
> 1. 在（6）中，已提交的日志可能在（8）中被完全覆盖
> 
> 2. 在（7）中，可能存在多个Leader节点被选出，导致脑裂，比如{S1,S4,S5}使用配置D和{S2,S3,S6}使用配置E

> 一阶段变更在网络分区下，也可能出现问题： https://zhuanlan.zhihu.com/p/342319702， 感兴趣的可以继续阅读。

这个问题出现在：

（1）成员变更过程中，Leader故障发生重新选主

（2）出现并发的成员变更请求，且成员变更配置未成功提交时，leader发送故障重新选主

解决思路：

（1）当上一个成员变更请求没有提交，Leader不能接受一个新的成员变更请求

更安全的做法，可以使用2PC来提交成员变更配置，是的全部节点都对这个配置达成共识后再继续服务

（2）只有在Leader成功提交成员变更时，返回客户端成功，如果客户端超时，需要重新确认集群配置或重做变更

* 注：具体工程时间参考etcd：[etcd learner design | etcd](https://etcd.io/docs/v3.5/learning/design-learner/)，etcd选择的是<font color='red'>二阶段成员变更</font>协议。

### 1.3.3 成员变更的其他问题和解决方案

1. 新成员日志落后问题（Learner的由来）
   
   - 问题
     
     在新加入的节点，可能本地确实较多数据，这个是有新节点无法追加新日志，容易导致日志无法提交，继而使得服务不可用
     
     S1: 1 2 3 (Leader)  
     S2: 1 2 3  
     S3: 1 2 3  
     S4:
     
     4节点要求多数派为3以上，一旦S1，S2，S3中有一个节点宕机，将导致新日志无法提交
- 解决方案
  
  在节点加入集群前，先以learner身份进行数据同步。
  
  > 新日志会一直产生，那么新节点何时才算追上Leader？
  > 
  > ![](/Users/panyongfeng/Documents/basic_framework/wiki/大数据系统/分布式系统/一致性问题/共识算法(副本一致性)/pics/1579829669.png)
  > 
  > 让当前leader最新数据作为最终的复制目标，当新节点到达这个位置之后，再把那个时间的leader最新日志设定为新目标，如此循环，工程上一般设定10个round就可以算是追上。当然也可以按照新节点和Leader的writerIndex来定。
2. 删除当前Leader
   
   - 问题
     
     如果新配置中，要求把正当Leader的节点剔除到集群外，那么，可能在某一段时间内，存在一个不属于集群的Leader进行着日志复制。
     
     S1: 1 2 3 (Leader)  
     S2: 1 2 3  
     S3: 1 2 3  
     S4: 1 2 3
     
     现在需要剔除S1节点，这个时候S1已经应用新配置，但依然需要把Cnew提交之后，才能移除释放Leader权限。
   
   - 可行方案
     
     如果Leader收到提出自身的成员变更方案，先转移Leader权限到其他节点后，让其他节点执行这个变更（但此时有可能没有其他节点可以成为Leader）

3. 干扰服务
   
   - 问题
     
     被剔除的节点，不再收到Leader的心跳和RPC，可能触发选举超时，发起选举。即使他不能成为Leader（他自己也不会投自己），但会打断服务流程，执行不必要的选举流程。
   
   - 解决方案
     
     Follower在没有到达选举超时之前，不接受其他Leader的选举请求。

4. 加入非法节点，导致服务不可用

5. 集群从单节点到双节点会触发一次选举

## 2 日志压缩

待补充，跟Paxos，2PC何时回收日志相似，过早回收会导致落后的节点无法获得连续的日志。

主要思路是：把存量数据压缩成一个快照数据，然后把快照数据复制过来，然后从快照位置继续复制增量日志。

2PC要求事务所有节点都提交成功后，才能滚掉该事务日志。

KRaft会在Leader上有一个已提交的日志水位，这个水位之前的事件表示已经被提交（依赖Raft的日志提交原则），并假设已提交日志所在节点不能全部故障（否则就丢数据了）。

Multi Paxos的Leader会维护其他节点的日志窗口，一个窗口内日志全部提交后才能进入下一个窗口的提议进程；Leader会定期广播日志confirm，让副本把已提交的日志应用到状态机，并且释放多余的日志空间（如果存在节点日志落后过多的时候怎么办？想Raft那样用复制快照？还是尽力避免副本间日志跨度过大？跨度过大的节点剔除集群外，成为learner，这又有点像Kafka的ISR）。

# 3 客户端交互

主要问题：如何保证读一致？对于不确定的数据是否提交，是否还要走一遍共识协议？怎么优化读性能？

实现参考：[etcd client design | etcd](https://etcd.io/docs/v3.5/learning/design-client/)

参考文献：

1. In search of an understandable consensus algorithm.pdf
   
   Raft精简版（早于论文发表，论文在这个基础上做了一些调整）

2. 2014-CONSENSUS- BRIDGING THEORY AND PRACTICE论文.pdf
   
   博士论文译文：[raft-thesis-zh_cn/raft-thesis-zh_cn.md at master · OneSizeFitsQuorum/raft-thesis-zh_cn · GitHub](https://github.com/OneSizeFitsQuorum/raft-thesis-zh_cn/blob/master/raft-thesis-zh_cn.md)

3. 2014-CONSENSUS- BRIDGING THEORY AND PRACTICE PPT.pdf
   
   博士论文ppt

4. riconwest2013.pdf
   
   斯坦福大学Raft讲义

5. Raft成员变更在etcd上遇到的疑问：[raft: liveness problems during apply-time configuration change · Issue #12359 · etcd-io/etcd · GitHub](https://github.com/etcd-io/etcd/issues/12359)（其实没有问题）

6. Raft单点成员变更在tidb上遇到的问题：https://zhuanlan.zhihu.com/p/342319702

7. etcd client概述：[etcd client design | etcd](https://etcd.io/docs/v3.5/learning/design-client/)

待阅读材料：

1. Analysis of Raft Consensus.pdf

2. quorum commit protocal.pdf
- 由于S2网络隔离导致S2转入Candidate状态，并发起多次选举，到了Term=3时，恢复通信，并且S2获得{S2,S3}的赞成票，当选Leader
  
  S1: 1 2 ({S1,S3} Vote, Leader)  
  S2: 1 2 ({S2,S3} Vote, Leader)  
  S3: 1 2
  
  因此，解决方法跟Multi Paxos一样，在Leader被选出后，会立即发送一个no-op事件来确认自己是否能上任Leader。
  
  事先说明下这个no-op事件的不同用途：（1）用于提交之前任期的日志（2）防止其他candidate发起选举（3）Leader确认自己上任（见其他小节）
  
  （2）选举失败
  
  同一时刻，可能有多个Candidate广播Vote RPC，如果大家都无法获得多数派支持，那么这一个Term的选举就被宣告失败。这个时候可能出现一个Term内可能完全没有内容可应用到状态机。
  
  ![](https://km.sankuai.com/api/file/cdn/1278777284/1578991635?contentType=1&isNewContent=false)
  
  出现选举失败，在网络正常的情况下，就是选票被瓜分到不同的Candidate中，Raft为了简化设计，让Candidate选举超时时间随机化（Paxos篇提及用于规避异步化模型的手段），来降低选票瓜分的概率。
  
  文中也提及，是否让节点间有优先级来选择Leader，但是论文解释说会有一点小问题，猜测是网络分区+成员变更的问题，有兴趣的同学可以继续深挖一下。
  
  ## 1.2 日志复制
  
  日志复制在Paxos篇已经提及，就是各个副本中维护一个状态机，每个操作作为一个操作日志记录到副本本地，如果各个副本中的操作日志完全一致（数量和顺序），那么应用到状态机后，状态机所处状态也是可以保证一致的。
  
  Leader通过AppendEntries RCP请求广播日志到各个副本节点，副本节点无条件信任Leader并写入本地日志。
  
  ![](https://km.sankuai.com/api/file/cdn/1278777284/1579231656?contentType=1&isNewContent=false&isNewContent=false)
  
  日志属性：
1. 日志所在位置log index

2. 日志被写入时的任期号term

3. 日志的操作记录
   
   为了讨论方便，下面讨论的时候都按下面的格式描述
   
   ![](https://km.sankuai.com/api/file/cdn/1278777284/1579773055?contentType=1&isNewContent=false&isNewContent=false)
   
   ### 1.2.1 日志一致性检查

4. 副本间日志如何保持一致？
   
   1. Leader被选出后，默认所有副本的日志与Leader本身一致（即，自身下一个日志可写位也是副本日志的下一个日志可写位）
   
   2. 当副本收到Leader发送过来的AppendEntries RPC，副本会检查Leader要写的logindex和该log的term，如果与Leader不一致则拒绝日志
      
      ![](https://km.sankuai.com/api/file/cdn/1278777284/1579707161?contentType=1&isNewContent=false&isNewContent=false)
   
   3. Leader的AppendEntries RPC被拒绝后，会尝试回退上一个日志位置，重试发送AppendEntries RPC，直到副本接受为止
      
      集群各副本的日志在某一时刻可能是下面的样子：
      
      ![](https://km.sankuai.com/api/file/cdn/1278777284/1579897439?contentType=1&isNewContent=false&isNewContent=false)
      
      Leader首先要找到各个副本与自己本身日志匹配的位置writeIndex后，重写或者填充副本的日志。
      
      ![](https://km.sankuai.com/api/file/cdn/1278777284/1580752223?contentType=1&isNewContent=false&isNewContent=false)
   
   Leader需要维护各个副本的日志写入位置writeIndex

5. 副本之间的日志如何比较“新”和“旧”
   
   Raft 通过比较两个副本日志中最后一条日志条目的索引值和任期号来定义谁的日志比较新。
   
   1. 如果两份日志最后条目的任期号不同，那么任期号大的日志更“新”
   
   2. 如果两份日志最后条目的任期号相同，那么拥有更多日志的那个更“新”（即副本的last log index大的更“新”）。
   
   ### 1.2.2 关于“日志提交”的问题
   
   日志什么时候才算被安全提交？
   
   ![](https://km.sankuai.com/api/file/cdn/1278777284/1566468574?contentType=1&isNewContent=false)
   
   （a）S1为Leader（Term=2），并将日志（Term=2, logIndex=2）广播到副本，但是没有达到多数派时，宕机（S1，S2的Term=2，S3，S4，S5的Term=1）
   
   （b）S5由{S3,S4,S5}投票选出作为Term=3的Leader，并收到一个请求，但S5仅添加到本地日志（Term=3, logindex=2）就宕机了（S1，S2的Term=2，S3，S4的Term=1，S5的Term=3）
   
   （c）S1恢复（Term=4），并可获得{S1,S2,S3,S4}的赞成票，S1重新成为Leader，并继续恢复其他副本的日志（Term=2，logindex=2），并接收到新的请求（Term=4，logindex=3）（S1，S2，S3的Term=4，S4的Term=1，S5的Term=3）
   
   然后根据日志复制原则，可能出现一下两种情形：
   
   （d1）S1宕机，S5因为持有（Term=3，logindex=2）的日志，所以，他比{S2,S3,S4}的日志都要“新”，所以S5顺利成章当选Leader（假设S5以Term=4进行投票，节点是允许应答Term相同的RPC请求），然后S5同步（Term=3, logindex=2）的日志重写所有副本的数据（S1，S2，S3，S4，S5的Term=4）
   
   （d2）S1继续运行，把（Term=4，logindex=3）的日志写入多数派，然后即使S1宕机，S5因为不具备最新日志，无法成为Leader
   
   这两种情形都符合Raft协议的要求，但是（d1）的情形，已经被多数副本写入的数据却可能被其他日志覆盖，所以，写多数派仅仅是Raft日志提交的必要条件。
   
   Raft日志还有一个规定：（1）Leader只能提交自己所在Term的日志（也就是说，自身Term的日志只要写多数派之后就算提交）（2）早期Term日志重新复制到其他副本时，保留原有的Term，且这些日志即使写多数派也不能算已提交
   
   这种场景对应于Paxos篇中，即使提议已经提交，当存在该日志的一个节点宕机，原本多数派的日志会变成少数派。
   
   Proposer： 1 2 3  
   ~~Acceptor1：1 2 3~~  
   Acceptor2：1 2
   
   当已提交的日志中有一个节点宕机，仅凭现状是无法得知日志是否被多数派接受
   
   外部视图：
   
   Proposer：1 2 3  
   Acceptor：1 2
   
   根据视图推断的场景：
   
   （1）场景1
   
   Proposer：1 2 3  
   Acceptor：1 2  
   Acceptor：1 2
   
   （2）场景2
   
   Proposer：1 2 3  
   Acceptor：1 2 3  
   Acceptor：1 2
   
   但是我们永远不知道是哪种场景，所以Paxos索性对这些不确定的日志进行“重确认”（reconfiguration）：重新投票决定
   
   Raft与Paxos的区别在于：1. Raft不允许日志空洞存在，如果有副本日志落后比较多，会导致副本长时间无法参与提交最新的日志；2. Raft一个位置的日志一旦提交，比这个位置更小的日志也是已提交的；
   
   所以Raft在新Leader当选后，可以立即发送一个no-op日志来提交之前任期的日志，而无需对之前的日志进行“重确认”（如果no-op日志还没提交，Leader就宕机，之前的日志相当于未提交，新Leader有权覆盖这些日志）。
   
   附：Leader选举安全性证明
   
   Leader选举安全性证明
   
   ![](https://km.sankuai.com/api/file/cdn/1278777284/1579450285?contentType=1&isNewContent=false&isNewContent=false)
   
   假设：任期 T 的 leader（leader T）在任期内提交了一个日志条目，但是该日志条目没有被存储到未来某些任期U的 leader 中（U>T），我们用反证法推断假设不成立。
   
   Leader选举的要求是新Leader的日志要比赞成者的日志“新”，“新”的定义是最后一个日志Term更大，如果Term一样就是logindex更大。
   
   有两种情况：

6. 如果Leader U最后一个日志term跟投票者一样，那么日志一定比投票者要多，而投票者要求多数派，必定与任期T的已提交日志节点重叠（图中的S3）那么肯定包含已提交的AE日志，这个跟假设矛盾。

7. 如果Leader U最后一个日志term比投票者大，那么比这个任期U小的已提交的日志应该都跟之前任期的leader一致，因为T<U，所以Leader U会包含Leader T的所有已提交日志，这个也跟假设矛盾。
   
   因此，我们的假设不成立，即新任期U必定包含任期T的全部已提交日志
   
   ## 1.3 成员变更
   
   ### 1.3.1 二阶段成员变更
   
   到目前为止，我们都假设集群的配置（参与一致性算法的服务器集合）是固定不变的。但是在实践中，偶尔会改变集群的配置的，例如替换那些宕机的机器或者改变复制程度。尽管可以通过使整个集群下线，更新所有配置，然后重启整个集群的方式来实现，但是在更改期间集群会不可用。另外，如果存在手工操作步骤，那么就会有操作失误的风险。为了避免这样的问题，配置变更自动化也纳入到 Raft 一致性算法中来。
   
   ![](https://km.sankuai.com/api/file/cdn/1278777284/1579361511?contentType=1&isNewContent=false&isNewContent=false)
   
   成员变更的配置同样是一个共识问题，但是在变更过程中，由于集群数量的变化，可能在共识过程中，不同的成员配置对多数派的要求不同，从而存在多个Leader在不同的成员配置中诞生，如上图（加入2个新节点）的：
- Cold：{S1, S2}，认为集群节点数是3个，多数派要求2个

- Cnew: {S3, S4, S5} ，认为集群节点数是5个，多数派要求3个
  
  （1）在《In Search of an Understandable Consensus Algorithm》文中，二阶段变更：
  
  Cold -> Cold,new -> Cnew，其中 Cold,new 是一个过渡态
  
  ![](https://km.sankuai.com/api/file/cdn/1278777284/1579397750?contentType=1&isNewContent=false&isNewContent=false)
  
  Server对成员配置，需要遵循下面的原则：
1. 当节点已收到成员配置变更请求，不管这个提案是否已经提交（同步到多数派），本节点立即按新配置执行（比如Leader收到新配置，新配置中不属于集群的节点，Leader就不会再发送RPC请求）
   
   在etcd的issue里，有用户提及二阶段成员变更问题：[raft: liveness problems during apply-time configuration change · Issue #12359 · etcd-io/etcd · GitHub](https://github.com/etcd-io/etcd/issues/12359)（learner的由来请看：[etcd learner design | etcd](https://etcd.io/docs/v3.5/learning/design-learner/)）
   
   不过这个issue的用户没有注意成员变更的原则：
   
   1. 成员配置变更是节点接收到后立即应用
   
   2. 不在集群的成员，如果收到RPC请求，是可以应答符合条件的请求的（不会根据成员名单应答）
   
   我们再看issue里列举的场景：
   
   Cold => voters: {A, B, C}, learners: {D}  
   Cnew => voters: {A, B, D}, learners: {C}  
   Cold,new => voters: {A, B, C, D}
   
   首先，A为Leader，B宕机，Leader收到成员变更请求并广播Cold,new到多数节点
   
   A: ... Cold,new, E … En … Em （Leader）  
   B: ...  
   C: ... Cold,new, E … En  
   D: ... Cold,new, E … En … Em
   
   然后，A宕机，B恢复，issue认为只有B、C可以进入Candidate并进行Leader选举，其实D已经应用Cold,new，已经不是learner状态，这时候D可以成为Leader（而B虽然在Cold，只认{A,B,C}，但是日志不比C新，无法成为Leader，而C应用Cold,new，认{A,B,C,D}，但是日志没有D新，所以不会被选为Leader）
   
   ~~A: ... Cold,new, E … En … Em~~  
   B: ...  
   C: ... Cold,new, E … En  
   D: ... Cold,new, E … En … Em （Leader）
   
   其他场景也能按上面的逻辑解释。

2. 在成员变更过程中，一旦发生选举，新Leader只可能在Cold或者Cold,new中被选出，所以Vote RPC可能会发往新加入的节点
   
   比如源集群有3个节点，现在需要增加2个节点，是的集群变为5节点
   
   S1: Cold (Leader)  
   S2: Cold  
   S3: Cold  
   S4:  
   S5:
   
   Leader收到新的配置请求Cnew = {S1,S2,S3,S4,S5}，Cold,new = Cold U Cnew = {S1,S2,S3,S4,S5}
   
   ~~S1: Cold,new (Leader)~~  
   S2: Cold  
   S3: Cold  
   S4: Cold,new  
   S5:
   
   当Leader宕机，新Leader可以在Cold: {S2, S3} 选出S2/S3 或者 Cold,new: {S4,S2,S3,S5}中选出S4，只不过在Cold中选出的Leader无法感知成员变更的事情（S4 会在选举超时后发起新一轮选举，但如果期间{S2,S3}有新日志提交，可能S4无法被选为主），这个时候发起成员变更请求的客户端应答确定集群状态并重新发起。

3. 成员变更需要共用一个日志记录，否则会出现已提交的数据丢失的情况
   
   data conf  
   S1: 1 2 C0 (Leader)  
   S2: 1 C0  
   S3: 1 C0  
   S4: 1 2 C0  
   S5: 1 2 C0
   
   然后收到C1 = {S1, S2, S3, S4}
   
   data conf  
   S1: 1 2 C0 C1 (Leader)  
   S2: 1 C0 C1  
   S3: 1 C0 C1  
   S4: 1 2 C0  
   S5: 1 2 C0 (leave)
   
   然后再收到C2 = {S1, S2, S3}
   
   data conf  
   S1: 1 2 C0 C1 C2 (Leader)  
   S2: 1 C0 C1 C2  
   S3: 1 C0 C1 C2  
   S4: 1 2 C0 C1 (leave)  
   S5: 1 2 C0 (leave)
   
   此时，一旦S1故障发生选主，假设S2被选出，然后提交新的日志，S1恢复
   
   data conf  
   S1: 1 3 C0 C1 C2  
   S2: 1 3 C0 C1 C2 (Leader)  
   S3: 1 3 C0 C1 C2  
   S4: 1 2 C0 C1 (leave)  
   S5: 1 2 C0 (leave)
   
   日志2被覆盖，已提交的数据丢失
   
   ### 1.3.2 一阶段成员变更
   
   在博士论文中，对二阶段成员变更，通过单节点成员变更，把二阶段优化成一阶段：Cold -> Cnew
   
   ![](https://km.sankuai.com/api/file/cdn/1278777284/1568546101?contentType=1&isNewContent=false&isNewContent=false)
   
   两种情况：
   
   （1）如果Cnew未过半前，Leader故障，可以从Cold上选出一个Leader服务，新Leader被选出后会先广播本term的no-op日志来提交之前的所有日志，所以原来的拥有Cnew的节点（旧term）无法被选出，Cold->Cnew的请求宣告失败；
   
   （2）如果Cnew过半，属于已提交，那么持有Cold的服务就无法再被选为Leader了，即使新Leader故障，新选出的Leader都会持有Cnew配置
   
   事实上，一阶段优化在并发成员变更可能带来脑裂（在不同的配置上出现多个leader），https://groups.google.com/g/raft-dev/c/t4xj6dJTP6E，下面拿其中一个例子说明：
   
   增加一个节点到4节点集群然后再增加一个节点，配置如下：
   
   C = {S1,S2,S3,S4}  
   D = {S1,S2,S3,S4,S5}  
   E = {S1,S2,S3,S4,S6}
   
   （1）集群初始状态：
   
   S1 (L1): [C]  
   S2 (F1): [C]  
   S3 (F1): [C]  
   S4 (F1): [C]  
   S5 (F1): []  
   S6 (F1): []
   
   （2）S1收到新成员配置请求D并应用
   
   S1 (L1): [C, D]  
   S2 (F1): [C]  
   S3 (F1): [C]  
   S4 (F1): [C]  
   S5 (F1): [C]
   
   （3）S1将日志D复制到S5后宕机
   
   ~~S1 (L1): [C, D]~~  
   S2 (F1): [C]  
   S3 (F1): [C]  
   S4 (F1): [C]  
   S5 (F1): [C, D]  
   S6 (F1): []
   
   （4）S2发起选举，并从{S2,S3,S4}中获得赞成票成为Leader
   
   ~~S1 (L1): [C, D]~~  
   S2 (L2): [C]  
   S3 (F2): [C]  
   S4 (F2): [C]  
   S5 (F1): [C, D]  
   S6 (F1): []
   
   （5）S2收到新成员配置请求E并应用
   
   ~~S1 (L1): [C, D]~~  
   S2 (L2): [C, E]  
   S3 (F2): [C]  
   S4 (F2): [C]  
   S5 (F1): [C, D]
   
   （6）S2将E复制到S3和S6，此时在配置E中是已提交的状态（可以假设还有其他的日志）
   
   ~~S1 (L1): [C, D]~~  
   S2 (L2): [C, E]  
   S3 (F2): [C, E]  
   S4 (F2): [C]  
   S5 (F1): [C, D]  
   S6 (F2): [C, E]
   
   （7）S1发起选举，并得到{S1,S4,S5}赞成成为Leader
   
   S1 (L3): [C, D]  
   S2 (L2): [C, E]  
   S3 (F2): [C, E]  
   S4 (F3): [C]  
   S5 (F3): [C, D]  
   S6 (F2): [C, E]
   
   （8）S1根据自身配置覆盖副本日志
   
   S1 (L3): [C, D]  
   S2 (L2): [C, D]  
   S3 (F2): [C, D]  
   S4 (F3): [C, D]  
   S5 (F3): [C, D]  
   S6 (F3): [C, D]
   
   上面的场景违背了两个地方：

4. 在（6）中，已提交的日志可能在（8）中被完全覆盖

5. 在（7）中，可能存在多个Leader节点被选出，导致脑裂，比如{S1,S4,S5}使用配置D和{S2,S3,S6}使用配置E
   
   一阶段变更在网络分区下，也可能出现问题：https://zhuanlan.zhihu.com/p/342319702，感兴趣的可以继续阅读。
   
   这个问题出现在：
   
   （1）成员变更过程中，Leader故障发生重新选主
   
   （2）出现并发的成员变更请求，且成员变更配置未成功提交时，leader发送故障重新选主
   
   解决思路：
   
   （1）当上一个成员变更请求没有提交，Leader不能接受一个新的成员变更请求
   
   更安全的做法，可以使用2PC来提交成员变更配置，是的全部节点都对这个配置达成共识后再继续服务
   
   （2）只有在Leader成功提交成员变更时，返回客户端成功，如果客户端超时，需要重新确认集群配置或重做变更
* 注：具体工程时间参考etcd：[etcd learner design | etcd](https://etcd.io/docs/v3.5/learning/design-learner/)，etcd选择的是二阶段成员变更协议。
  
  ### 1.3.3 成员变更的其他问题和解决方案
1. 新成员日志落后问题（Learner的由来）
   
   - 问题
     
     在新加入的节点，可能本地确实较多数据，这个是有新节点无法追加新日志，容易导致日志无法提交，继而使得服务不可用
     
     S1: 1 2 3 (Leader)  
     S2: 1 2 3  
     S3: 1 2 3  
     S4:
     
     4节点要求多数派为3以上，一旦S1，S2，S3中有一个节点宕机，将导致新日志无法提交
- 解决方案
  
  在节点加入集群前，先以learner身份进行数据同步。
  
  新日志会一直产生，那么新节点何时才算追上Leader？
  
  ![](https://km.sankuai.com/api/file/cdn/1278777284/1579829670?contentType=1&isNewContent=false)
  
  让当前leader最新数据作为最终的复制目标，当新节点到达这个位置之后，再把那个时间的leader最新日志设定为新目标，如此循环，工程上一般设定10个round就可以算是追上。当然也可以按照新节点和Leader的writerIndex来定。
2. 删除当前Leader
   
   - 问题
     
     如果新配置中，要求把正当Leader的节点剔除到集群外，那么，可能在某一段时间内，存在一个不属于集群的Leader进行着日志复制。
     
     S1: 1 2 3 (Leader)  
     S2: 1 2 3  
     S3: 1 2 3  
     S4: 1 2 3
     
     现在需要剔除S1节点，这个时候S1已经应用新配置，但依然需要把Cnew提交之后，才能移除释放Leader权限。
   
   - 可行方案
     
     如果Leader收到提出自身的成员变更方案，先转移Leader权限到其他节点后，让其他节点执行这个变更（但此时有可能没有其他节点可以成为Leader）

3. 干扰服务
   
   - 问题
     
     被剔除的节点，不再收到Leader的心跳和RPC，可能触发选举超时，发起选举。即使他不能成为Leader（他自己也不会投自己），但会打断服务流程，执行不必要的选举流程。
   
   - 解决方案
     
     Follower在没有到达选举超时之前，不接受其他Leader的选举请求。

4. 加入非法节点，导致服务不可用

5. 集群从单节点到双节点会触发一次选举
   
   ## 2 日志压缩
   
   待补充，跟Paxos，2PC何时回收日志相似，过早回收会导致落后的节点无法获得连续的日志。
   
   主要思路是：把存量数据压缩成一个快照数据，然后把快照数据复制过来，然后从快照位置继续复制增量日志。
   
   2PC要求事务所有节点都提交成功后，才能滚掉该事务日志。
   
   KRaft会在Leader上有一个已提交的日志水位，这个水位之前的事件表示已经被提交（依赖Raft的日志提交原则），并假设已提交日志所在节点不能全部故障（否则就丢数据了）。
   
   Multi Paxos的Leader会维护其他节点的日志窗口，一个窗口内日志全部提交后才能进入下一个窗口的提议进程；Leader会定期广播日志confirm，让副本把已提交的日志应用到状态机，并且释放多余的日志空间（如果存在节点日志落后过多的时候怎么办？想Raft那样用复制快照？还是尽力避免副本间日志跨度过大？跨度过大的节点剔除集群外，成为learner，这又有点像Kafka的ISR）。
   
   # 3 客户端交互
   
   主要问题：如何保证读一致？对于不确定的数据是否提交，是否还要走一遍共识协议？怎么优化读性能？
   
   实现参考：[etcd client design | etcd](https://etcd.io/docs/v3.5/learning/design-client/)

   参考文献：

1. In search of an understandable consensus algorithm.pdf
   
   Raft精简版（早于论文发表，论文在这个基础上做了一些调整）

2. 2014-CONSENSUS- BRIDGING THEORY AND PRACTICE论文.pdf
   
   博士论文译文：[raft-thesis-zh_cn/raft-thesis-zh_cn.md at master · OneSizeFitsQuorum/raft-thesis-zh_cn · GitHub](https://github.com/OneSizeFitsQuorum/raft-thesis-zh_cn/blob/master/raft-thesis-zh_cn.md)

3. 2014-CONSENSUS- BRIDGING THEORY AND PRACTICE PPT.pdf
   
   博士论文ppt

4. riconwest2013.pdf
   
   斯坦福大学Raft讲义

5. Raft成员变更在etcd上遇到的疑问：[raft: liveness problems during apply-time configuration change · Issue #12359 · etcd-io/etcd · GitHub](https://github.com/etcd-io/etcd/issues/12359)（其实没有问题）

6. Raft单点成员变更在tidb上遇到的问题： https://zhuanlan.zhihu.com/p/342319702

7. etcd client概述：[etcd client design | etcd](https://etcd.io/docs/v3.5/learning/design-client/)
   
   待阅读材料：

8. Analysis of Raft Consensus.pdf

9. quorum commit protocal.pdf
